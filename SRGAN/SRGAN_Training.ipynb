{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Configuration",
   "id": "46e8e407c7f5b00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the transformations on the data\n",
    "low_res_size = 128\n",
    "high_res_size = 512\n",
    "\n",
    "transform_low = transforms.Compose([\n",
    "    transforms.Resize((low_res_size, low_res_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_high = transforms.Compose([\n",
    "    transforms.Resize((high_res_size, high_res_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 100\n",
    "NUM_WORKERS = 2"
   ],
   "id": "4c11371763cd197c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Classes",
   "id": "97f71f94f24c7903"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, discriminator=False, use_act=True, use_bn=True, **kwargs):\n",
    "        #use_act = True ** should activation function be defined? True then yes\n",
    "        super().__init__()\n",
    "        self.use_act = use_act\n",
    "        self.cnn = nn.Conv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "        self.act = (\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "            if discriminator\n",
    "            else nn.PReLU(num_parameters=out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))"
   ],
   "id": "af7917a5611537d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * scale_factor ** 2, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(in_channels * scale_factor ** 2)\n",
    "        self.ps = nn.PixelShuffle(scale_factor)\n",
    "        self.act = nn.PReLU(num_parameters=in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.ps(self.conv(x)))"
   ],
   "id": "7ec588af8ef1e282",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.block1 = ConvBlock(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.block2 = ConvBlock(in_channels, in_channels, kernel_size=3, stride=1, padding=1, use_act=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        return out + x"
   ],
   "id": "bd0953b74958d176",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_channels=64, num_blocks=16):\n",
    "        super().__init__()\n",
    "        self.initial = ConvBlock(in_channels, num_channels, kernel_size=9, stride=1, padding=4, use_bn=False)\n",
    "        self.residuals = nn.Sequential(*[ResidualBlock(num_channels) for i in range(num_blocks)])\n",
    "        self.conv = ConvBlock(num_channels, num_channels, kernel_size=3, stride=1, padding=1, use_act=False)\n",
    "        self.upsamples = nn.Sequential(UpsampleBlock(num_channels, scale_factor=2),UpsampleBlock(num_channels, scale_factor=2))\n",
    "        self.final = nn.Conv2d(num_channels, in_channels, kernel_size=9, stride=1, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.residuals(initial)\n",
    "        x = self.conv(x) + initial\n",
    "        x = self.upsamples(x)\n",
    "        return torch.tanh(self.final(x))"
   ],
   "id": "e53d5027e4c49b60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        for index, feature in enumerate(features):\n",
    "            blocks.append(\n",
    "                ConvBlock(in_channels, feature, kernel_size=3, stride=1 + index % 2, padding=1, discriminator=True,\n",
    "                          use_act=True, use_bn=False if index == 0 else True))\n",
    "            in_channels = feature\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d((6, 6)), nn.Flatten(), nn.Linear(512 * 6 * 6, 1024),\n",
    "                                        nn.LeakyReLU(0.2, inplace=True), nn.Linear(1024, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "def test():\n",
    "    low_resolution = 24\n",
    "    with torch.amp.autocast('cuda'):\n",
    "        x = torch.randn((5, 3, low_resolution, low_resolution))\n",
    "        gen = Generator()\n",
    "        gen_out = gen(x)\n",
    "        disc = Discriminator()\n",
    "        disc_out = disc(gen_out)\n",
    "        return gen_out, disc_out\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ],
   "id": "74a7f6fc399bc9f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loss (from SRGAN_Loss)",
   "id": "509a5c5a6da80650"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1)\n",
    "IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1)\n",
    "\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vgg = vgg19(weights=VGG19_Weights.IMAGENET1K_V1).features[:36].eval()\n",
    "        for p in self.vgg.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # input/target are in [-1, 1] -> convert to [0, 1]\n",
    "        input_01  = (input  + 1) / 2\n",
    "        target_01 = (target + 1) / 2\n",
    "\n",
    "        mean = IMAGENET_MEAN.to(input.device)\n",
    "        std  = IMAGENET_STD.to(input.device)\n",
    "\n",
    "        input_n  = (input_01  - mean) / std\n",
    "        target_n = (target_01 - mean) / std\n",
    "\n",
    "        f_in  = self.vgg(input_n)\n",
    "        f_tgt = self.vgg(target_n)\n",
    "        return self.loss(f_in, f_tgt)\n"
   ],
   "id": "a2e8f74150e046c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset (from SRGAN_Dataset)",
   "id": "4c2498aa49f58903"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SRGANDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform_low, transform_high):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform_low = transform_low\n",
    "        self.transform_high = transform_high\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[index])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Create both versions from the same image\n",
    "        high_res = self.transform_high(img)\n",
    "        low_res = self.transform_low(img)\n",
    "\n",
    "        return low_res, high_res"
   ],
   "id": "c6d4b1b44562d1f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training loop",
   "id": "cc17f99d5a8802a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!ls ./data/DIV2K_train_HR/",
   "id": "f795dd2ef9322d5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "gen = Generator(in_channels=3).to(DEVICE)\n",
    "disc = Discriminator(in_channels=3).to(DEVICE)\n",
    "\n",
    "# Optimizers\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n",
    "\n",
    "# Loss functions\n",
    "vgg_loss = VGGLoss().to(DEVICE)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "train_dataset = SRGANDataset(\n",
    "    root_dir='./data/DIV2K_train_HR/DIV2K_train_HR/',\n",
    "    transform_low=transform_low,\n",
    "    transform_high=transform_high\n",
    ")\n",
    "\n",
    "val_dataset = SRGANDataset(\n",
    "    root_dir='./data/DIV2K_valid_HR/DIV2K_valid_HR/',\n",
    "    transform_low=transform_low,\n",
    "    transform_high=transform_high\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "\n",
    "def train_one_epoch(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    # Track losses across ALL batches\n",
    "    total_gen_loss = 0\n",
    "    total_disc_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for idx, (low_res, high_res) in enumerate(loop):\n",
    "        low_res = low_res.to(DEVICE)\n",
    "        high_res = high_res.to(DEVICE)\n",
    "\n",
    "        ### Train Discriminator ###\n",
    "        fake = gen(low_res)\n",
    "        disc_real = disc(high_res)\n",
    "        disc_fake = disc(fake.detach())\n",
    "\n",
    "        disc_loss_real = bce(disc_real, torch.ones_like(disc_real))\n",
    "        disc_loss_fake = bce(disc_fake, torch.zeros_like(disc_fake))\n",
    "        disc_loss = disc_loss_real + disc_loss_fake\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator ###\n",
    "        fake = gen(low_res)\n",
    "        disc_fake = disc(fake)\n",
    "\n",
    "        adversarial_loss = bce(disc_fake, torch.ones_like(disc_fake))  # Remove 1e-3 here\n",
    "        perceptual_loss = vgg(fake, high_res)\n",
    "        content_loss = mse_loss(fake, high_res)\n",
    "\n",
    "        gen_loss = content_loss + 0.1 * perceptual_loss + 1e-3 * adversarial_loss\n",
    "\n",
    "\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Accumulate losses\n",
    "        total_gen_loss += gen_loss.item()\n",
    "        total_disc_loss += disc_loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_postfix(\n",
    "            gen_loss=gen_loss.item(),\n",
    "            disc_loss=disc_loss.item()\n",
    "        )\n",
    "\n",
    "    # Return AVERAGE loss across all batches\n",
    "    return total_gen_loss / num_batches, total_disc_loss / num_batches\n",
    "\n",
    "\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    gen_loss, disc_loss = train_one_epoch(\n",
    "        train_loader, disc, gen, opt_gen, opt_disc,\n",
    "        mse_loss, bce_loss, vgg_loss\n",
    "    )\n",
    "\n",
    "    d_losses.append(disc_loss)\n",
    "    g_losses.append(gen_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(gen.state_dict(), f'generator_epoch_{epoch + 1}.pth')\n",
    "        torch.save(disc.state_dict(), f'discriminator_epoch_{epoch + 1}.pth')\n",
    "        print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "\n",
    "    # Plot progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(d_losses, label='Discriminator Loss')\n",
    "        plt.plot(g_losses, label='Generator Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training Progress')\n",
    "        plt.show()\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "torch.save(gen.state_dict(), 'generator_final.pth')\n",
    "torch.save(disc.state_dict(), 'discriminator_final.pth')\n",
    "print(\"Final models saved!\")"
   ],
   "id": "db40322587276009",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "def denormalize(tensor):\n",
    "    return (tensor * 0.5) + 0.5\n",
    "\n",
    "# Get one batch of test images\n",
    "gen.eval()\n",
    "with torch.no_grad():\n",
    "    low_res, high_res = next(iter(val_loader))\n",
    "    low_res = low_res.to(DEVICE)\n",
    "    high_res = high_res.to(DEVICE)\n",
    "\n",
    "    # Generate SR images\n",
    "    sr_images = gen(low_res)\n",
    "\n",
    "    # Take first 3 images from batch\n",
    "    for i in range(min(3, low_res.size(0))):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        # Low-res (upscaled with bicubic)\n",
    "        lr_np = denormalize(low_res[i]).cpu().numpy().transpose(1, 2, 0)\n",
    "        lr_upscaled = np.array(Image.fromarray((lr_np * 255).astype(np.uint8)).resize((128, 128), Image.BICUBIC)) / 255.0\n",
    "        axes[0].imshow(lr_upscaled)\n",
    "        axes[0].set_title('Bicubic Upscale')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # SRGAN output\n",
    "        sr_np = denormalize(sr_images[i]).cpu().numpy().transpose(1, 2, 0)\n",
    "        axes[1].imshow(np.clip(sr_np, 0, 1))\n",
    "        axes[1].set_title('SRGAN Output')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        # High-res ground truth\n",
    "        hr_np = denormalize(high_res[i]).cpu().numpy().transpose(1, 2, 0)\n",
    "        axes[2].imshow(np.clip(hr_np, 0, 1))\n",
    "        axes[2].set_title('Ground Truth')\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        # Calculate PSNR (ADD THESE 3 LINES HERE)\n",
    "        psnr_bicubic = psnr(hr_np, lr_upscaled)\n",
    "        psnr_srgan = psnr(hr_np, np.clip(sr_np, 0, 1))\n",
    "        print(f\"Image {i}: Bicubic PSNR = {psnr_bicubic:.2f} dB, SRGAN PSNR = {psnr_srgan:.2f} dB\")\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'comparison_{i}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "gen.train()"
   ],
   "id": "b7a05736fa12d799",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
